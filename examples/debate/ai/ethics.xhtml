<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml"
	xmlns:dc="http://purl.org/dc/elements/1.1/" 
	xmlns:rdfs="http://www.w3.org/2000/01/rdf-schema#"
	xmlns:skos="http://www.w3.org/2004/02/skos/core#"
	xmlns:time="https://www.w3.org/TR/owl-time/"
	xmlns:ies="http://ies.data.gov.uk/ies4#"
	xmlns:core="https://knoxa.github.io/ai#"
	>
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8" />
<link type="text/css" href="master.css" rel="stylesheet"/>
<title>Ethics</title>
<link rel="schema.DC" href="http://purl.org/dc/elements/1.1/"/>
<meta name="DC.source" content="The Elephant and the Fly"/>
<meta name="DC.identifier" content="Example ..."/>
</head>
<body>
<h2>Ethics</h2>

<a href="https://www.unesco.org/en/artificial-intelligence/recommendation-ethics">UNESCO</a>

<div>
<p>Core principles:</p>
<ol>

<li>
<strong>Proportionality and Do No Harm</strong>
<p>
The use of AI systems must not go beyond what is necessary to achieve a legitimate aim. Risk assessment should be used to prevent harms which may result from such uses.
</p>
</li>

<li>
<strong>Safety and Security</strong>
<p>
Unwanted harms (safety risks) as well as vulnerabilities to attack (security risks) should be avoided and addressed by AI actors.
</p>
</li>

<li>
<strong>Right to Privacy and Data Protection</strong>
<p>
Privacy must be protected and promoted throughout the AI lifecycle. Adequate data protection frameworks should also be established.
</p>
</li>

<li>
<strong>Multi-stakeholder and Adaptive Governance &amp; Collaboration</strong>
<p>
International law &amp; national sovereignty must be respected in the use of data. Additionally, participation of diverse stakeholders is necessary for inclusive approaches to AI governance.
</p>
</li>

<li>
<strong>Responsibility and Accountability</strong>
<p>
AI systems should be auditable and traceable. There should be oversight, impact assessment, audit and due diligence mechanisms in place to avoid conflicts with human rights norms and threats to environmental wellbeing.
</p>
</li>

<li>
<strong>Transparency and Explainability</strong>
<p>
The ethical deployment of AI systems depends on their transparency &amp; explainability (T&amp;E). The level of T&amp;E should be appropriate to the context, as there may be tensions between T&amp;E and other principles such as privacy, safety and security.
</p>
</li>

<li>
<strong>Human Oversight and Determination</strong>
<p>
Member States should ensure that AI systems do not displace ultimate human responsibility and accountability.
</p>
</li>

<li>
<strong>Sustainability</strong>
<p>
AI technologies should be assessed against their impacts on ‘sustainability’, understood as a set of constantly evolving goals including those set out in the UN’s Sustainable Development Goals.
</p>
</li>

<li>
<strong>Awareness &amp; Literacy</strong>
<p>
Public understanding of AI and data should be promoted through open &amp; accessible education, civic engagement, digital skills &amp; AI ethics training, media &amp; information literacy.
</p>
</li>

<li>
<strong>Fairness and Non-Discrimation</strong>
<p>
AI actors should promote social justice, fairness, and non-discrimination while taking an inclusive approach to ensure AI’s benefits are accessible to all.
</p>
</li>

</ol>
</div>

<article>


</article>

</body>

</html>